{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "nb_path = os.getcwd()\n",
    "proj_path = nb_path.split('Notebooks')[0]\n",
    "tools_path = proj_path + \"/Analysis_Tools\"\n",
    "sys.path.insert(0, tools_path)\n",
    "from Parsers import Game_Predictor\n",
    "from Setup import Directory_setup\n",
    "from importlib import reload\n",
    "reload(Game_Predictor)\n",
    "reload(Directory_setup)\n",
    "\n",
    "setup = Directory_setup.Create_Directories()\n",
    "project_path = setup.project_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2020 NFL Weekly Game Predictions\n",
    "#### This Notebook makes spread picks based on the Expected Game Outcome (EGO) as calculated by our DVOA Model trained on Data from the 2006-2019 NFL seasons.\n",
    "<br>\n",
    "<br>\n",
    "Below is the Data and Predictions for this week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Week: 8 Games ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Prediction_Helper' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f65421d8ae17>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mweek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mseason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2020\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mData\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame_Predictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNFL_Game_Predictor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdateType\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Week'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mSpread_Target_DF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSpread_Targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nWeek {week} Evaluation:\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Seagate Bac/Project Stuff/NFL Data Analysis/NFL Game Predictor V1//Analysis_Tools/Parsers/Game_Predictor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, project_path, current_week, current_season, updateType, Enable_Messaging)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Analyzing Week: {week} Games ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m#Get the Raw Data we need\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRaw_Game_Data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGet_Game_Info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessed_Game_Data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess_Game_Info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRaw_Game_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalculated_Game_Data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCalculate_Game_Info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcessed_Game_Data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Seagate Bac/Project Stuff/NFL Data Analysis/NFL Game Predictor V1//Analysis_Tools/Parsers/Game_Predictor.py\u001b[0m in \u001b[0;36mGet_Game_Info\u001b[0;34m(self, raw_data_path, week)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUser_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Retrieving Scheudle and Scores for week {week} ...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;31m#Get the schedule for the week\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mgame_info_collector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPrediction_Helper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGame_Info_Parser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mWeek_DF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgame_info_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeek_Sched_DF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;31m# print(Week_DF)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Prediction_Helper' is not defined"
     ]
    }
   ],
   "source": [
    "week = 8\n",
    "season = 2020\n",
    "Data = Game_Predictor.NFL_Game_Predictor(project_path, week, season, updateType='Week')\n",
    "Spread_Target_DF = Data.Spread_Targets\n",
    "print(f'\\nWeek {week} Evaluation:\\n')\n",
    "print(Spread_Target_DF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How The Model is Built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Model is trained with Data on every game from 2006 to 2019 by looking at the spread, the score and the Teams' WDVOA Difference for each game week 6 and later. WDVOA is a measure of a teams' overall strength that takes into account all facets of the game and is weighted toward the more recent performances. This stat is published every week by football outsiders. The premmise of the model is as follows:\n",
    "1. Log the score and Teams' WDVOA difference for every game.\n",
    "2. Create a \"Map\" of average scoring margin and WDVOA Difference such that for any game with WDVOA Difference X we can find an expected score Y. This is our Expected Game Outcome (EGO).\n",
    "3. Divide this map by Home and Away Teams. Teams playing at home have an advantage that is not considered in the WDVOA stat so we need to seperate the predictions according to whether the teams are home and away.\n",
    "<br>\n",
    "<br>\n",
    "The resultant Map/Model can be viewed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = pd.read_csv('Models/All Seasons Scores Grouped By WDVOA Diff.csv')\n",
    "map #Delete \"#\" at beginning of line to show output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model\n",
    "With this model we can make a pick for every game in our 2006-2019 dataset by comparing our EGO to the spread and determing the Pick accordingly. The assigned Pick was then assessed relative to the actual outcome of the game to determine if right or wrong. \n",
    "<br>\n",
    "<br>\n",
    "The results of this evaluation are shown in the demonstation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the Data Path\n",
    "DVOA_Type = 'WDVOA'\n",
    "Total_Prediction_Data_Path = f'{proj_path}/Data/Total Data/ALL {DVOA_Type} Model Data.csv'\n",
    "#Read the Data\n",
    "dataset = pd.read_csv(Total_Prediction_Data_Path)\n",
    "#Defien the columns needed for this evaluation\n",
    "evaluation_df = dataset[['DVOA Pick Right', 'DVOA EGO to Spread Diff']].sort_values(by='DVOA EGO to Spread Diff', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Dataframe and Lists to Store REsults\n",
    "results_df = pd.DataFrame()\n",
    "accuracy_data = []\n",
    "avg_ego_data = []\n",
    "legend_data = []\n",
    "\n",
    "#Get Betting accuracy by EGO to Spread Difference for each moving average window\n",
    "moving_windows = [250, 500]\n",
    "for moving_avg in moving_windows:\n",
    "    legend = f'{DVOA_Type} Based Betting Accuracy - {moving_avg} points MA'\n",
    "    ego_data = list(evaluation_df['DVOA EGO to Spread Diff'])\n",
    "    prediction_data = list(evaluation_df['DVOA Pick Right'])\n",
    "    counter=0\n",
    "    for dp in range(0,len(ego_data)-moving_avg):\n",
    "        avg_egoDiff = sum(ego_data[dp:(dp+moving_avg)])/moving_avg\n",
    "        avg_acc = ((sum(prediction_data[dp:(dp+moving_avg)])/2)+(moving_avg/2))/moving_avg\n",
    "        avg_ego_data.append(avg_egoDiff)\n",
    "        accuracy_data.append(avg_acc)\n",
    "        counter+=1\n",
    "    legend_data += [legend for i in range(counter)]\n",
    "    \n",
    "#Store results into final dataframe\n",
    "results_df['Betting Accuracy'] = accuracy_data\n",
    "results_df['EGO to Spread Diff'] = avg_ego_data\n",
    "results_df['Analysis Name'] = legend_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = (px.scatter(results_df, x=\"EGO to Spread Diff\", y=\"Betting Accuracy\", color=\"Analysis Name\").update_traces(mode='lines+markers', line=dict(width=1), marker=dict(size=3),))\n",
    "fig.update_layout(dict(plot_bgcolor='rgba(0,0,0,0)', paper_bgcolor='rgba(0,0,0,0)'))\n",
    "fig.show(renderer='notebook')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Games were our expected score and the spread differ by 1.5 to 3.7 points, we see a 55-59% success rate in our picks against the spread. For Games where our EGO are within 1.5 points of the spread, we sit at a 48 to 50% acuracy while games where our EGO is greater than 3.7 off from the spread, our accuracy declines as this difference grows. <br>\n",
    "<br>\n",
    "We atribute these results to indicate that when the Spread and EGO are matching (within 1.5 points), the spread is appropriate and thus there is an even 50% chance of covering the spread. Contrastingly, when our EGO differs by the spread by too much, our accuracy declines because there is something our model has failed to take into account, like an injury, so we see a decline in Accuracy in this case. The sweet spot occurs when our EGO differs by the spread enough that we have gained an advantage not factored in by the spread but not due to much that we it's attributed to unaccounted events. In this range we see a sustainable betting acuracy\n",
    "<br>\n",
    "<br>\n",
    "Thus, when we pick games, we will look for opportunites where the EGO differs from the spread by between 1.5 to 3.7 points to maximize our chances of being in this sweet spot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
